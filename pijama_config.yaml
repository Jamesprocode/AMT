# ── Data paths ────────────────────────────────────────────────────────────────
data_dir: PiJAMa/midi_kong      # folder to read .midi files from (midi or midi_kong)
output_dir: data/pijama         # where train.txt / valid.txt are written

# ── Preprocessing ─────────────────────────────────────────────────────────────
augment_factor: 1               # 1 = autoregressive only
                                # 10 = full anticipation augmentation (spans + random)
seed: 42
workers: 8                      # parallel CPU workers for preprocessing (default: all cores)

# ── Model ─────────────────────────────────────────────────────────────────────
model: model/music-medium-800k   # HF model ID or local checkpoint path
lora: true                               # true = LoRA (~8GB VRAM), false = full finetune (~24GB)
checkpoint_dir: checkpoints/pijama      # where to save checkpoints
resume_from_checkpoint: null            # set to a checkpoint path to resume, e.g. checkpoints/pijama/checkpoint-1000

# ── Training hyperparameters ──────────────────────────────────────────────────
epochs: 10
batch_size: 32                  # per-device; H100 80GB can handle this easily
grad_accum: 1                   # effective batch = batch_size * grad_accum (= 32)
lr: 3.0e-5                      # scaled up with batch size (sqrt rule: 1e-5 * sqrt(8) ≈ 3e-5)

# ── Checkpointing ─────────────────────────────────────────────────────────────
save_steps: 1000                # save a checkpoint every N steps
save_total_limit: 5             # keep only the N most recent checkpoints (+ best)
eval_steps: 200                 # evaluate every N steps (finer-grained loss curve)

# ── Sampling / logging ────────────────────────────────────────────────────────
sample_every_steps: 500         # generate a MIDI audio sample every N steps and log to W&B
sample_length: 10               # length of generated sample in seconds

# ── W&B ───────────────────────────────────────────────────────────────────────
wandb_project: amt-pijama
wandb_run: amt-pijama-first try                 # null = auto-generated name
